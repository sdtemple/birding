{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c8f362",
   "metadata": {},
   "source": [
    "## This is starter code for single point prediction with CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3eb762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# common math imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# common torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# common sklearn imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0b133",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e074dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor covariate data (audio processing)\n",
    "X = torch.load('data/bc22-32/X_tensor.pt')\n",
    "\n",
    "# meta data information\n",
    "metadata = pd.read_csv('data/bc22-32/orig_metadata.csv')\n",
    "filtdata = pd.read_csv('data/bc22-32/train_metadata_cleaned.csv')\n",
    "files = np.loadtxt('data/bc22-32/files.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d383246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor target data (classification labels)\n",
    "# by zero crossing rate inferences\n",
    "# which is strong labeling\n",
    "# assuming that my zcr algorithm is correct\n",
    "y = torch.load('data/bc22-32/y_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486d8056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or, this tensor target data can be created from the metadata\n",
    "# by encoding the file names\n",
    "# which is weak labeling\n",
    "# assuming that most all timeslices have a bird\n",
    "file_encoder = LabelEncoder()\n",
    "files_ = [file.split('/')[-2] for file in files]\n",
    "y = file_encoder.fit_transform(files_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc89b586",
   "metadata": {},
   "source": [
    "## Some simple CNN models\n",
    "\n",
    "Note that you can use these for multilabel or single categorical label classification, which will depend on your choice of target and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea4414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Simple Convolutional Neural Network for audio classification.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, in_channels=1, \n",
    "                 out_channels1=16, out_channels2=32,\n",
    "                 fc_hidden_units=64, \n",
    "                 kernel_size=3, stride=1, padding=1,\n",
    "                 pooling_size=2, dropout=0.5):\n",
    "        \"\"\"Initialize Simple Convolutional Neural Network for audio classification.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes : int\n",
    "            Number of output classes for classification.\n",
    "        in_channels : int, optional\n",
    "            Number of input channels (default is 1 for grayscale audio).\n",
    "        out_channels1 : int, optional\n",
    "            Number of output channels for the first convolutional layer.\n",
    "        out_channels2 : int, optional\n",
    "            Number of output channels for the second convolutional layer.\n",
    "        fc_hidden_units : int, optional\n",
    "            Number of hidden units in the fully connected layer.\n",
    "        kernel_size : int or tuple, optional\n",
    "            Size of the convolutional kernel.\n",
    "        stride : int or tuple, optional\n",
    "            Stride of the convolutional operation.\n",
    "        padding : int or tuple, optional\n",
    "            Padding added to the input tensor.\n",
    "        pooling_size : int or tuple, optional\n",
    "            Size of the pooling operation.\n",
    "        dropout : float, optional\n",
    "            Dropout rate for regularization (default is 0.5).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels1, \n",
    "                               kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.conv2 = nn.Conv2d(out_channels1, out_channels2, \n",
    "                               kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.pool = nn.MaxPool2d(pooling_size, pooling_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.LazyLinear(fc_hidden_units)\n",
    "        self.fc2 = nn.Linear(fc_hidden_units, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the SimpleCNN model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor of shape (batch_size, in_channels, height, width).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Output tensor of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a212e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchMichiganCNN(nn.Module):\n",
    "    \"\"\"SchMichiganCNN: A Convolutional Neural Network for audio classification.\n",
    "    This model is designed to process audio data represented as spectrograms or sonograms.\n",
    "    It includes multiple convolutional layers, pooling layers, and fully connected layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 num_classes,\n",
    "                 height=32,\n",
    "                 width=50,\n",
    "                 kernel_sizes=[3,3],\n",
    "                 padding_sizes=[1,1],\n",
    "                 stride_sizes=[1,1],\n",
    "                 pooling_kernels=[(2,2),(2,2)],\n",
    "                 pooling_strides=[(2,2),(2,2)],\n",
    "                 channel_sizes=[64,64], \n",
    "                 fc_sizes=[64,64],\n",
    "                 fc_activation=F.relu,\n",
    "                 dropout=0.5,\n",
    "                 batchNormalization=False, \n",
    "                 leakyRelu=False, \n",
    "                 ):\n",
    "        \"\"\"Initialize the SchMichiganCNN model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes : int\n",
    "            Number of output classes for classification.\n",
    "        height : int, optional\n",
    "            Height of the input spectrogram (default is 32).\n",
    "        width : int, optional\n",
    "            Width of the input spectrogram (default is 50).\n",
    "        kernel_sizes : list of int or tuple, optional\n",
    "            List of kernel sizes for each convolutional layer.\n",
    "        padding_sizes : list of int or tuple, optional\n",
    "            List of padding sizes for each convolutional layer.\n",
    "        stride_sizes : list of int or tuple, optional\n",
    "            List of stride sizes for each convolutional layer.\n",
    "        pooling_kernels : list of int or tuple, optional\n",
    "            List of pooling kernel sizes for each pooling layer.\n",
    "        pooling_strides : list of int or tuple, optional\n",
    "            List of pooling stride sizes for each pooling layer.\n",
    "        channel_sizes : list of int, optional\n",
    "            List of output channel sizes for each convolutional layer.\n",
    "        fc_sizes : list of int, optional\n",
    "            List of sizes for the fully connected layers.\n",
    "        fc_activation : callable, optional\n",
    "            Activation function for the fully connected layers (default is ReLU).\n",
    "        dropout : float, optional\n",
    "            Dropout rate for regularization (default is 0.5).\n",
    "        batchNormalization : bool, optional\n",
    "            Whether to apply batch normalization after each convolutional layer (default is False).\n",
    "        leakyRelu : bool, optional\n",
    "            Whether to use Leaky ReLU activation instead of ReLU (default is False).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(SchMichiganCNN, self).__init__()\n",
    "\n",
    "        # Validate input parameters\n",
    "        assert len(kernel_sizes) > 0, \"At least one kernel size must be provided\"\n",
    "        ks = kernel_sizes\n",
    "        ps = padding_sizes\n",
    "        ss = stride_sizes\n",
    "        nm = channel_sizes\n",
    "        pks = pooling_kernels\n",
    "        pss = pooling_strides\n",
    "        assert len(ks) == len(ps) == len(ss) == len(nm), \\\n",
    "            \"Kernel sizes, padding sizes, stride sizes, and channel sizes must have the same length\"\n",
    "        assert len(pks) == len(pss) == len(nm), \\\n",
    "            \"Pooling kernel sizes and pooling stride sizes must match the number of channel sizes\" \n",
    "\n",
    "        # Define the CNN layers\n",
    "        cnn = nn.Sequential()\n",
    "        nIn = 1 # Assuming sonogram input is 1 dimensional\n",
    "        out_height, out_width = height, width\n",
    "        for i in range(len(nm)):\n",
    "            nOut = nm[i]\n",
    "            # Add a convolutional layer\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            # Calculate output height and width after this conv layer\n",
    "            out_height = (out_height + 2 * ps[i] - ks[i]) // ss[i] + 1\n",
    "            out_width = (out_width + 2 * ps[i] - ks[i]) // ss[i] + 1\n",
    "\n",
    "            # Add batch normalization if specified\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "\n",
    "            # Add activation function\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "\n",
    "            # Add the pooling layer\n",
    "            pooling_kernel = pooling_kernels[i]\n",
    "            pooling_stride = pooling_strides[i]\n",
    "            cnn.add_module('pooling{0}'.format(i), nn.MaxPool2d(pooling_kernel, pooling_stride))\n",
    "            # Update output height and width after pooling\n",
    "            out_height = (out_height - pooling_kernel[0]) // pooling_stride[0] + 1\n",
    "            out_width = (out_width - pooling_kernel[1]) // pooling_stride[1] + 1\n",
    "\n",
    "            # Add dropout if specified\n",
    "            if dropout > 0:\n",
    "                cnn.add_module('dropout{0}'.format(i), nn.Dropout(dropout))\n",
    "\n",
    "            # Update input channels for the next layer\n",
    "            nIn = nOut\n",
    "\n",
    "        # Save the CNN layers and output dimensions\n",
    "        self.cnn = cnn\n",
    "        self.height = out_height\n",
    "        self.width = out_width\n",
    "\n",
    "        # Define the fully connected layers\n",
    "        assert len(fc_sizes) == 2, \"Can only have 2 fully connected layers\"\n",
    "        self.fc1 = nn.Linear(nm[-1] * out_height * out_width, fc_sizes[0])\n",
    "        # self.fc1 = nn.LazyLinear(fc_sizes[0])\n",
    "        self.fc2 = nn.Linear(fc_sizes[1], num_classes)\n",
    "        self.fc_activation = fc_activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the SchMichiganCNN model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor of shape (batch_size, in_channels, height, width).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Output tensor of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), -1) # x.size(0) is the batch size\n",
    "        x = self.fc_activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81720e3",
   "metadata": {},
   "source": [
    "## Reset categorical labels if analyzing a bird subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de3a465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze common species only\n",
    "categories = filtdata['primary_label'].value_counts()[:5].index.tolist()\n",
    "filtdata_v2 = filtdata[filtdata['primary_label'].isin(categories)]\n",
    "common_labels = filtdata_v2['filename'].unique()\n",
    "files_v2 = ['/'.join(file.split('/')[2:]) for file in files]\n",
    "bools = np.isin(files_v2, common_labels)\n",
    "X2 = X[bools]\n",
    "y2 = y[bools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9bdce990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the common species don't have 1 - 10 labels\n",
    "# Get unique values and create mapping\n",
    "unique_vals = np.unique(y2)\n",
    "val_to_new = {old.item(): new for new, old in enumerate(unique_vals)}\n",
    "\n",
    "# Remap y2 using the mapping\n",
    "y2_mapped = torch.tensor([val_to_new[val.item()] for val in y2], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f474461",
   "metadata": {},
   "source": [
    "## Make train-test split and one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c3b7a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 16741\n",
      "Testing data size: 4186\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "\n",
    "X2 = X2.float()\n",
    "num_classes = y2_mapped.unique().numel()\n",
    "y_onehot = F.one_hot(y2_mapped, num_classes=num_classes)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X2, y_onehot, test_size=0.2, stratify=y2_mapped, random_state=42\n",
    ")\n",
    "\n",
    "# Print the sizes of the splits\n",
    "print(f\"Training data size: {X_train.shape[0]}\")\n",
    "print(f\"Testing data size: {X_test.shape[0]}\")\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2999fc",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab76f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Conv2d parameters: 9568\n",
      "Total Fully Connected (Linear) parameters: 98534\n",
      "\n",
      "SchMichiganCNN(\n",
      "  (cnn): Sequential(\n",
      "    (conv0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pooling0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (dropout0): Dropout(p=0.5, inplace=False)\n",
      "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (pooling1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=3072, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "num_classes = len(y2_mapped.unique())  # Number of unique categories in y_encoded\n",
    "cnn_model = SchMichiganCNN(num_classes,\n",
    "                           channel_sizes=[32, 32],\n",
    "                           fc_sizes=[32, 32],\n",
    "                           batchNormalization=False,)\n",
    "# cnn_model = SimpleCNN(num_classes,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c63b89",
   "metadata": {},
   "source": [
    "#### Report the size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(cnn_model) == SchMichiganCNN:\n",
    "    conv_params = 0\n",
    "    fc_params = 0\n",
    "\n",
    "    for name, param in cnn_model.named_parameters():\n",
    "        if 'conv' in name:\n",
    "            conv_params += param.numel()\n",
    "        elif 'fc' in name:\n",
    "            fc_params += param.numel()\n",
    "\n",
    "    print(f\"Total Conv2d parameters: {conv_params}\")\n",
    "    print(f\"Total Fully Connected (Linear) parameters: {fc_params}\")\n",
    "    print()\n",
    "\n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd11b03",
   "metadata": {},
   "source": [
    "## Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4af62b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "num_epochs = 10  # Number of epochs to train\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "criterion = nn.BCEWithLogitsLoss()  # Suitable for multi-label classification\n",
    "\n",
    "# Choose an optimizer for training\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.01)  # You can adjust the learning rate\n",
    "\n",
    "# Alternatively, use SGD optimizer\n",
    "# optimizer = optim.SGD(cnn_model.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ea892",
   "metadata": {},
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e7da9958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.4417\n",
      "Epoch 2/10, Loss: 0.3832\n",
      "Epoch 3/10, Loss: 0.3618\n",
      "Epoch 4/10, Loss: 0.3410\n",
      "Epoch 5/10, Loss: 0.3309\n",
      "Epoch 6/10, Loss: 0.3200\n",
      "Epoch 7/10, Loss: 0.3139\n",
      "Epoch 8/10, Loss: 0.3099\n",
      "Epoch 9/10, Loss: 0.3058\n",
      "Epoch 10/10, Loss: 0.2969\n"
     ]
    }
   ],
   "source": [
    "# # Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = cnn_model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091b17b",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1de898b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model\n",
      "Training Accuracy (all labels): 41.65%\n",
      "Training Accuracy (single label): 42.61%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's accuracy on the training data\n",
    "cnn_model.eval()  # Set the model to evaluation mode\n",
    "correct1 = 0\n",
    "correct2 = 0\n",
    "total1 = 0\n",
    "total2 = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = cnn_model(inputs)\n",
    "\n",
    "        # Get the predicted class (index of the maximum value in the output)\n",
    "        # For multi-label (one-hot) targets, use sigmoid and threshold at 0.5\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        predicted = (probs > 0.5).int()\n",
    "        labels = labels.int()\n",
    "        # print((predicted == labels).all(dim=1).float().mean().item())\n",
    "\n",
    "        # Update total and correct counts\n",
    "        # For multi-label accuracy, count samples where all labels match\n",
    "        correct1 += (predicted == labels).all(dim=1).sum().item()\n",
    "        total1 += labels.size(0)\n",
    "        correct2 += ((predicted == labels) * labels).sum()\n",
    "        total2 += labels.size(0)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy1 = correct1 / total1 * 100\n",
    "accuracy2 = correct2 / total2 * 100\n",
    "print(\"CNN model\")\n",
    "print(f\"Training Accuracy (all labels): {accuracy1:.2f}%\")\n",
    "print(f\"Training Accuracy (single label): {accuracy2:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "21038125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model\n",
      "Testing Accuracy (all labels): 42.47%\n",
      "Testing Accuracy (single label): 43.43%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's accuracy on the training data\n",
    "cnn_model.eval()  # Set the model to evaluation mode\n",
    "correct1 = 0\n",
    "correct2 = 0\n",
    "total1 = 0\n",
    "total2 = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = cnn_model(inputs)\n",
    "\n",
    "        # Get the predicted class (index of the maximum value in the output)\n",
    "        # For multi-label (one-hot) targets, use sigmoid and threshold at 0.5\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        predicted = (probs > 0.5).int()\n",
    "        labels = labels.int()\n",
    "        # print((predicted == labels).all(dim=1).float().mean().item())\n",
    "\n",
    "        # Update total and correct counts\n",
    "        # For multi-label accuracy, count samples where all labels match\n",
    "        correct1 += (predicted == labels).all(dim=1).sum().item()\n",
    "        total1 += labels.size(0)\n",
    "        correct2 += ((predicted == labels) * labels).sum()\n",
    "        total2 += labels.size(0)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy1 = correct1 / total1 * 100\n",
    "accuracy2 = correct2 / total2 * 100\n",
    "print(\"CNN model\")\n",
    "print(f\"Testing Accuracy (all labels): {accuracy1:.2f}%\")\n",
    "print(f\"Testing Accuracy (single label): {accuracy2:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdclef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
