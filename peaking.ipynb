{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e42ec19",
   "metadata": {},
   "source": [
    "## This file summarizes much of the audio data\n",
    "which is too long to fit NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common general imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# common math imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# common audio imports\n",
    "import librosa\n",
    "from scipy.signal import hilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0833efd5",
   "metadata": {},
   "source": [
    "## Custom functions to get summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# differentiator\n",
    "def differentiate(signal):\n",
    "    return np.diff(signal, prepend=0)\n",
    "\n",
    "# get the summary statistics\n",
    "def calculate_summary_statistics(audio, sr, print_summary=False):\n",
    "    \"\"\"\n",
    "    Calculate and print summary statistics for an audio file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        audio (numpy.ndarray): The audio time series.\n",
    "        sr (int): The sample rate of the audio file.\n",
    "        print_summary (bool): If True, prints the summary statistics.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        dict: A dictionary containing summary statistics.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    if sr == 0:\n",
    "        duration = 0\n",
    "    else:\n",
    "        duration = len(audio) / sr\n",
    "    mean_amplitude = np.mean(np.abs(audio))\n",
    "    std_amplitude = np.std(audio)\n",
    "    highest_peak = np.max(audio)\n",
    "    lowest_valley = np.min(audio)\n",
    "    energy = np.sum(audio ** 2)\n",
    "\n",
    "    # Print summary statistics\n",
    "    if print_summary:\n",
    "        print(f\"Duration: {duration:.2f} seconds\")\n",
    "        print(f\"Mean Amplitude: {mean_amplitude:.4f}\")\n",
    "        print(f\"Standard Deviation of Amplitude: {std_amplitude:.4f}\")\n",
    "        print(f\"Highest Peak: {highest_peak:.4f}\")\n",
    "        print(f\"Lowest Valley: {lowest_valley:.4f}\")\n",
    "        print(f\"Energy: {energy:.4f}\")\n",
    "\n",
    "    # Save summary statistics to a dictionary\n",
    "    dictionary = dict()\n",
    "    dictionary['duration'] = duration\n",
    "    dictionary['mean_amplitude'] = mean_amplitude\n",
    "    dictionary['std_amplitude'] = std_amplitude\n",
    "    dictionary['highest_peak'] = highest_peak\n",
    "    dictionary['lowest_valley'] = lowest_valley\n",
    "    dictionary['energy'] = energy\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1050a4a0",
   "metadata": {},
   "source": [
    "## Custom functions to subset to the peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0fe852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def max_in_windows(data, percentage=2):\n",
    "    \"\"\"This function computes max in non-overlapping windows of data comprising percentage of the data length.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        The input data to be processed.\n",
    "    percentage : int, optional\n",
    "        The percentage of the data length to be used for each window. Default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Array of maximum values found in each window.\n",
    "    \"\"\"\n",
    "    assert percentage > 0, \"percentage must be greater than 0\"\n",
    "    window_size = int(len(data) * percentage / 100)\n",
    "    return np.array([np.max(data[i:i + window_size]) for i in range(0, len(data), window_size)])\n",
    "\n",
    "def argmax_in_windows(data, percentage=2):\n",
    "    \"\"\"This function computes the index of the maximum value in non-overlapping windows of data comprising percentage of the data length.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        The input data to be processed.\n",
    "    percentage : int, optional\n",
    "        The percentage of the data length to be used for each window. Default is 2.\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Array of indices of maximum values found in each window.\n",
    "    \"\"\"\n",
    "    assert percentage > 0, \"percentage must be greater than 0\"\n",
    "    window_size = int(len(data) * percentage / 100)\n",
    "    return np.array([np.argmax(data[i:i + window_size]) for i in range(0, len(data), window_size)])\n",
    "\n",
    "def peak_scan(data, percentage=2, num_peaks=5):\n",
    "    \"\"\"This function scans the data for peaks based on the maximum values in non-overlapping windows.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        The input data to be processed.\n",
    "    percentage : int, optional\n",
    "        The percentage of the data length to be used for each window. Default is 2.\n",
    "    num_peaks : int, optional\n",
    "        The number of peaks to be returned. Default is 5.\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Array of indices of the peaks found in the data.\n",
    "    \"\"\"\n",
    "    assert num_peaks > 0, \"num_peaks must be greater than 0\"\n",
    "    assert percentage > 0, \"percentage must be greater than 0\"\n",
    "    max_values = max_in_windows(data, percentage)\n",
    "    argmax_values = argmax_in_windows(data, percentage)\n",
    "    window_size = int(len(data) * percentage / 100)\n",
    "    peak_sorting = np.argsort(max_values)[::-1]\n",
    "    peak_argmaxs = np.array(argmax_values)[peak_sorting]\n",
    "    wind_starts = np.arange(0, len(data), window_size)\n",
    "    wind_starts = wind_starts[peak_sorting]\n",
    "    peak_argmaxs = peak_argmaxs + wind_starts\n",
    "    return np.sort(peak_argmaxs[:num_peaks]) # do not break the temporal order of the peaks\n",
    "\n",
    "def peak_data(data, percentage=2, num_peaks=5, peak_width=100):\n",
    "    \"\"\"This function extracts data around the peaks found in the data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        The input data to be processed.\n",
    "    percentage : int, optional\n",
    "        The percentage of the data length to be used for each window. Default is 2.\n",
    "    num_peaks : int, optional\n",
    "        The number of peaks to be returned. Default is 5.\n",
    "    peak_width : int, optional\n",
    "        The width around each peak. Default is 100.\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Array of data segments around the peaks found in the data.\n",
    "    \"\"\"\n",
    "    assert num_peaks > 0, \"num_peaks must be greater than 0\"\n",
    "    assert peak_width > 0, \"plateau_size must be greater than 0\"\n",
    "    assert percentage > 0, \"percentage must be greater than 0\"\n",
    "    peaks = peak_scan(data, percentage, num_peaks)\n",
    "    start_of_data = 0\n",
    "    end_of_data = len(data)\n",
    "    half_width = peak_width // 2\n",
    "    peaks = np.clip(peaks, half_width, end_of_data - half_width)\n",
    "    return np.array([data[p-half_width:p+half_width] for p in peaks])\n",
    "\n",
    "def peak_zero_data(data, percentage=2, num_peaks=5, peak_width=100, rift_prop=0.2):\n",
    "    \"\"\"This function extracts data around the peaks and zero imputed stretches found in the data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        The input data to be processed.\n",
    "    percentage : int, optional\n",
    "        The percentage of the data length to be used for each window. Default is 2.\n",
    "    num_peaks : int, optional\n",
    "        The number of peaks to be returned. Default is 5.\n",
    "    peak_width : int, optional\n",
    "        The width around each peak. Default is 100.\n",
    "    rift_prop : float, optional\n",
    "        The proportion of the peak width to be used for the zeros rift. Default is 0.2.\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Array of data segments around the peaks and valleys found in the data.\n",
    "    \"\"\"\n",
    "    assert num_peaks > 0, \"num_peaks must be greater than 0\"\n",
    "    assert peak_width > 0, \"plateau_size must be greater than 0\"\n",
    "    assert percentage > 0, \"percentage must be greater than 0\"\n",
    "    assert 0 < rift_prop < 1, \"rift_prop must be between 0 and 1\"\n",
    "    peaked = peak_data(data, percentage, num_peaks, peak_width)\n",
    "    rift_size = int(peak_width * rift_prop)\n",
    "    rifted = np.array([np.zeros(rift_size) for _ in range(num_peaks)])\n",
    "    return np.concatenate((peaked, rifted), axis=1).flatten()[:-rift_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbae5b3",
   "metadata": {},
   "source": [
    "## Process and summarize the audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368416d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apapan\n",
      "arcter\n",
      "bcnher\n",
      "belkin1\n"
     ]
    }
   ],
   "source": [
    "# Get the .ogg files for all the data\n",
    "# And summarize the data\n",
    "pz_data = []\n",
    "sm_stat = []\n",
    "fn_list = []\n",
    "files_in_directories = {}\n",
    "directories = os.listdir('small/train_audio')\n",
    "for d in directories:\n",
    "    dir_path = os.path.join('small/train_audio', d)\n",
    "    files_in_directories[d] = os.listdir(dir_path)\n",
    "    print(d)\n",
    "    for file in files_in_directories[d]:\n",
    "        assert file.endswith('.ogg')\n",
    "        fn_list.append(file)\n",
    "        sm_file = []\n",
    "        # audio is Amplitude over time\n",
    "        audio, sr = librosa.load(dir_path + '/' + file, sr=None)\n",
    "        print(dir_path + '/' + file)\n",
    "        # compute data around the peaks\n",
    "        pz = peak_zero_data(audio, \n",
    "                            percentage=2, \n",
    "                            num_peaks=5, \n",
    "                            peak_width=100, \n",
    "                            rift_prop=0.2)\n",
    "        pz_data.append(pz)\n",
    "        # compute summary statistics for the peak data\n",
    "        sm = list(calculate_summary_statistics(pz, 0, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        pz_diff = differentiate(pz)\n",
    "        sm = list(calculate_summary_statistics(pz_diff, 0, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        # compute summary statistics for whole signal\n",
    "        sm = list(calculate_summary_statistics(audio, sr, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        # fourier transform to frequency domain\n",
    "        ft = np.fft.fft(audio)\n",
    "        real_ft = ft.real\n",
    "        sm = list(calculate_summary_statistics(real_ft, sr, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        imag_ft = ft.imag\n",
    "        sm = list(calculate_summary_statistics(imag_ft, sr, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        # hilbert transform to get the envelope\n",
    "        hilbert_transform = hilbert(audio)\n",
    "        sm = list(calculate_summary_statistics(hilbert_transform, sr, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        # differentiate the current array signals\n",
    "        differentiated_amplitude = differentiate(audio)\n",
    "        sm = list(calculate_summary_statistics(differentiated_amplitude, sr, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        differentiated_hilbert = differentiate(hilbert_transform)\n",
    "        sm = list(calculate_summary_statistics(differentiated_hilbert, sr, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        differentiated_real_ft = differentiate(real_ft)\n",
    "        sm = list(calculate_summary_statistics(differentiated_real_ft, sr, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        differentiated_imag_ft = differentiate(imag_ft)\n",
    "        sm = list(calculate_summary_statistics(differentiated_imag_ft, sr, print_summary=False).values())\n",
    "        sm_file += sm\n",
    "        sm_stat.append(sm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c67c6be",
   "metadata": {},
   "source": [
    "## Formatting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_header = ['peak_zero',\n",
    "                'peak_zero_diff',\n",
    "                'amplitude',\n",
    "                'real_ft',\n",
    "                'imag_ft',\n",
    "                'hilbert',\n",
    "                'amplitude_diff',\n",
    "                'hilbert_diff',\n",
    "                'real_ft_diff',\n",
    "                'imag_ft_diff']\n",
    "\n",
    "stats = ['duration',\n",
    "         'mean',\n",
    "         'std',\n",
    "         'highest_peak',\n",
    "         'lowest_valley',\n",
    "         'energy']\n",
    "header = []\n",
    "for macro in macro_header:\n",
    "    # for each macro, add the stats\n",
    "    # to the header\n",
    "    lst = [macro + '_' + stat for stat in stats]\n",
    "    header += lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63a2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>duration</th>\n",
       "      <th>peak_zero_mean</th>\n",
       "      <th>peak_zero_std</th>\n",
       "      <th>peak_zero_highest_peak</th>\n",
       "      <th>peak_zero_lowest_valley</th>\n",
       "      <th>peak_zero_energy</th>\n",
       "      <th>peak_zero_diff_mean</th>\n",
       "      <th>peak_zero_diff_std</th>\n",
       "      <th>peak_zero_diff_highest_peak</th>\n",
       "      <th>...</th>\n",
       "      <th>real_ft_diff_mean</th>\n",
       "      <th>real_ft_diff_std</th>\n",
       "      <th>real_ft_diff_highest_peak</th>\n",
       "      <th>real_ft_diff_lowest_valley</th>\n",
       "      <th>real_ft_diff_energy</th>\n",
       "      <th>imag_ft_diff_mean</th>\n",
       "      <th>imag_ft_diff_std</th>\n",
       "      <th>imag_ft_diff_highest_peak</th>\n",
       "      <th>imag_ft_diff_lowest_valley</th>\n",
       "      <th>imag_ft_diff_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XC174948.ogg</td>\n",
       "      <td>38.243250</td>\n",
       "      <td>0.151990</td>\n",
       "      <td>0.216105</td>\n",
       "      <td>0.992628</td>\n",
       "      <td>-0.963724</td>\n",
       "      <td>27.091248</td>\n",
       "      <td>0.113797</td>\n",
       "      <td>0.165857</td>\n",
       "      <td>1.043870</td>\n",
       "      <td>...</td>\n",
       "      <td>13.707000</td>\n",
       "      <td>26.772697</td>\n",
       "      <td>334.546875</td>\n",
       "      <td>-334.546875</td>\n",
       "      <td>8.771806e+08</td>\n",
       "      <td>13.689127</td>\n",
       "      <td>26.697587</td>\n",
       "      <td>328.448135</td>\n",
       "      <td>-314.644638</td>\n",
       "      <td>8.722657e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XC175215.ogg</td>\n",
       "      <td>14.341219</td>\n",
       "      <td>0.233658</td>\n",
       "      <td>0.285162</td>\n",
       "      <td>0.607250</td>\n",
       "      <td>-0.621231</td>\n",
       "      <td>47.173536</td>\n",
       "      <td>0.171163</td>\n",
       "      <td>0.207382</td>\n",
       "      <td>0.434898</td>\n",
       "      <td>...</td>\n",
       "      <td>7.836101</td>\n",
       "      <td>22.523485</td>\n",
       "      <td>345.603882</td>\n",
       "      <td>-345.603882</td>\n",
       "      <td>2.328130e+08</td>\n",
       "      <td>7.953264</td>\n",
       "      <td>23.254620</td>\n",
       "      <td>408.218399</td>\n",
       "      <td>-427.950836</td>\n",
       "      <td>2.481730e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XC175230.ogg</td>\n",
       "      <td>148.532250</td>\n",
       "      <td>0.546276</td>\n",
       "      <td>0.656852</td>\n",
       "      <td>1.063305</td>\n",
       "      <td>-1.056722</td>\n",
       "      <td>250.399190</td>\n",
       "      <td>0.343752</td>\n",
       "      <td>0.432396</td>\n",
       "      <td>1.221716</td>\n",
       "      <td>...</td>\n",
       "      <td>65.529773</td>\n",
       "      <td>178.978908</td>\n",
       "      <td>3540.982910</td>\n",
       "      <td>-3540.982910</td>\n",
       "      <td>1.522560e+11</td>\n",
       "      <td>65.605512</td>\n",
       "      <td>179.281997</td>\n",
       "      <td>3535.464722</td>\n",
       "      <td>-3566.416504</td>\n",
       "      <td>1.527721e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XC175233.ogg</td>\n",
       "      <td>14.341219</td>\n",
       "      <td>0.234857</td>\n",
       "      <td>0.286215</td>\n",
       "      <td>0.603929</td>\n",
       "      <td>-0.617128</td>\n",
       "      <td>47.522922</td>\n",
       "      <td>0.171730</td>\n",
       "      <td>0.208231</td>\n",
       "      <td>0.438015</td>\n",
       "      <td>...</td>\n",
       "      <td>7.834081</td>\n",
       "      <td>22.513999</td>\n",
       "      <td>345.951843</td>\n",
       "      <td>-345.951843</td>\n",
       "      <td>2.326169e+08</td>\n",
       "      <td>7.952280</td>\n",
       "      <td>23.244117</td>\n",
       "      <td>408.175674</td>\n",
       "      <td>-427.277283</td>\n",
       "      <td>2.479489e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XC175507.ogg</td>\n",
       "      <td>40.960000</td>\n",
       "      <td>0.116559</td>\n",
       "      <td>0.143177</td>\n",
       "      <td>0.305063</td>\n",
       "      <td>-0.291694</td>\n",
       "      <td>11.895361</td>\n",
       "      <td>0.080883</td>\n",
       "      <td>0.099590</td>\n",
       "      <td>0.230464</td>\n",
       "      <td>...</td>\n",
       "      <td>10.530685</td>\n",
       "      <td>29.492226</td>\n",
       "      <td>636.557098</td>\n",
       "      <td>-636.557098</td>\n",
       "      <td>1.140053e+09</td>\n",
       "      <td>10.510605</td>\n",
       "      <td>29.428464</td>\n",
       "      <td>578.873428</td>\n",
       "      <td>-618.538666</td>\n",
       "      <td>1.135129e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file    duration  peak_zero_mean  peak_zero_std  \\\n",
       "0  XC174948.ogg   38.243250        0.151990       0.216105   \n",
       "1  XC175215.ogg   14.341219        0.233658       0.285162   \n",
       "2  XC175230.ogg  148.532250        0.546276       0.656852   \n",
       "3  XC175233.ogg   14.341219        0.234857       0.286215   \n",
       "4  XC175507.ogg   40.960000        0.116559       0.143177   \n",
       "\n",
       "   peak_zero_highest_peak  peak_zero_lowest_valley  peak_zero_energy  \\\n",
       "0                0.992628                -0.963724         27.091248   \n",
       "1                0.607250                -0.621231         47.173536   \n",
       "2                1.063305                -1.056722        250.399190   \n",
       "3                0.603929                -0.617128         47.522922   \n",
       "4                0.305063                -0.291694         11.895361   \n",
       "\n",
       "   peak_zero_diff_mean  peak_zero_diff_std  peak_zero_diff_highest_peak  ...  \\\n",
       "0             0.113797            0.165857                     1.043870  ...   \n",
       "1             0.171163            0.207382                     0.434898  ...   \n",
       "2             0.343752            0.432396                     1.221716  ...   \n",
       "3             0.171730            0.208231                     0.438015  ...   \n",
       "4             0.080883            0.099590                     0.230464  ...   \n",
       "\n",
       "   real_ft_diff_mean  real_ft_diff_std  real_ft_diff_highest_peak  \\\n",
       "0          13.707000         26.772697                 334.546875   \n",
       "1           7.836101         22.523485                 345.603882   \n",
       "2          65.529773        178.978908                3540.982910   \n",
       "3           7.834081         22.513999                 345.951843   \n",
       "4          10.530685         29.492226                 636.557098   \n",
       "\n",
       "   real_ft_diff_lowest_valley  real_ft_diff_energy  imag_ft_diff_mean  \\\n",
       "0                 -334.546875         8.771806e+08          13.689127   \n",
       "1                 -345.603882         2.328130e+08           7.953264   \n",
       "2                -3540.982910         1.522560e+11          65.605512   \n",
       "3                 -345.951843         2.326169e+08           7.952280   \n",
       "4                 -636.557098         1.140053e+09          10.510605   \n",
       "\n",
       "   imag_ft_diff_std  imag_ft_diff_highest_peak  imag_ft_diff_lowest_valley  \\\n",
       "0         26.697587                 328.448135                 -314.644638   \n",
       "1         23.254620                 408.218399                 -427.950836   \n",
       "2        179.281997                3535.464722                -3566.416504   \n",
       "3         23.244117                 408.175674                 -427.277283   \n",
       "4         29.428464                 578.873428                 -618.538666   \n",
       "\n",
       "   imag_ft_diff_energy  \n",
       "0         8.722657e+08  \n",
       "1         2.481730e+08  \n",
       "2         1.527721e+11  \n",
       "3         2.479489e+08  \n",
       "4         1.135129e+09  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_stat_df = pd.DataFrame(sm_stat, columns=header)\n",
    "sm_stat_df['file'] = fn_list\n",
    "not_duration = [_ for _ in header if _.split('_')[-1] != 'duration']\n",
    "sm_stat_df['duration'] = sm_stat_df['amplitude_duration']\n",
    "cols = ['file', 'duration'] + not_duration\n",
    "sm_stat_df = sm_stat_df[cols]\n",
    "sm_stat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da3ad445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 580)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pz_array = np.array(pz_data)\n",
    "pz_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce043378",
   "metadata": {},
   "source": [
    "## Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecaa4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('peak_zero_data.npy', pz_array)\n",
    "sm_stat_df.to_csv('summary_statistics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whitesalmon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
